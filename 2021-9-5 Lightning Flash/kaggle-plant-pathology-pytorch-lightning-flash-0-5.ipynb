{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [Plant Pathology with Lightning ⚡ : by Jirka](https://www.kaggle.com/jirkaborovec/plant-pathology-with-lightning)\n",
    "2. [Plant Pathology - PyTorch Lightning ⚡️: by Aniket](https://www.kaggle.com/aniketmaurya/plant-pathology-pytorch-lightning/comments) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation (you might have to restart the kernel)\n",
    "```\n",
    "!pip install -U 'lightning-flash[image]'==0.5.0rc0 -q\n",
    "!pip install -U torchvision\n",
    "!pip install -U torchtext\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U 'lightning-flash[image]'==0.5.0rc0 -q\n",
    "!pip install -U torchvision\n",
    "!pip install -U torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import flash\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.metrics import FBeta\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/kaggle/input/plant-pathology-2021-fgvc8/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir/'train.csv')\n",
    "df['label_org'] = df.labels.values\n",
    "df.labels = df.labels.str.split()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: Jirka\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "labels_all = list(itertools.chain(*[lbs.split(\" \") for lbs in df['label_org']]))\n",
    "\n",
    "ax = sns.countplot(y=sorted(labels_all), orient='v')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 32\n",
    "IMAGE_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: Jirka\n",
    "from torchvision import transforms as T\n",
    "\n",
    "TRAIN_TRANSFORM = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.RandomPerspective(),\n",
    "    T.RandomResizedCrop(IMAGE_SIZE),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "VALID_TRANSFORM = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(IMAGE_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "TEST_TRANSFORM = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(IMAGE_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "mlb = mlb.fit(df.labels)\n",
    "def create_ohe(df, mlb):    \n",
    "    ohe = mlb.transform(df.labels)\n",
    "    ohe = pd.DataFrame.sparse.from_spmatrix(ohe, columns=mlb.classes_)\n",
    "    df = df.merge(ohe, left_index=True, right_index=True)\n",
    "    return df\n",
    "df = create_ohe(df, mlb)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.9\n",
    "frac = int(split * len(df))\n",
    "\n",
    "train_data = df[:frac]\n",
    "val_data = df[frac:]\n",
    "\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_data = val_data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, data, transformation, folder='train'):\n",
    "        self.data = data\n",
    "        self.transform = transformation\n",
    "        self.folder = folder\n",
    "    \n",
    "    def __len__(self): return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        folder = self.folder\n",
    "        file = data_dir/f\"{folder}_images/{self.data.loc[idx, 'image']}\"\n",
    "        image = Image.open(file)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        labels = self.data.iloc[idx, 3:].to_numpy().astype(int)\n",
    "        return {\"input\": image, \"target\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PlantDataset(train_data, TRAIN_TRANSFORM)\n",
    "val_dataset = PlantDataset(val_data, VALID_TRANSFORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mproc\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class PlantPathologyDM(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_dataset: Dataset = None,\n",
    "        val_dataset: Dataset = None,\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers if num_workers is not None else mproc.cpu_count()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.valid_dataset = val_dataset\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def num_classes(self) -> int:\n",
    "        return num_classes\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valid_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = PlantPathologyDM(train_dataset, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick view\n",
    "# fig = plt.figure(figsize=(3, 7))\n",
    "# for data in dm.train_dataloader():\n",
    "#     imgs = data[\"input\"]\n",
    "#     lbs = data[\"target\"]\n",
    "#     print(f'batch labels: {torch.sum(lbs, axis=0)}')\n",
    "#     print(f'image size: {imgs[0].shape}')\n",
    "#     for i in range(3):\n",
    "#         ax = fig.add_subplot(3, 1, i + 1, xticks=[], yticks=[])\n",
    "#         # print(np.rollaxis(imgs[i].numpy(), 0, 3).shape)\n",
    "#         ax.imshow(np.rollaxis(imgs[i].numpy(), 0, 3))\n",
    "#         ax.set_title(lbs[i])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "i = 0\n",
    "for label in tqdm(df.labels):\n",
    "    labels.extend(label)\n",
    "labels = set(labels)\n",
    "num_classes = len(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_with_logits(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Calls BCE with logits and cast the target one_hot (y) encoding to floating point precision.\"\"\"\n",
    "    return F.binary_cross_entropy_with_logits(x, y.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier(\n",
    "    dm.num_classes,\n",
    "    'ssl_resnet50',\n",
    "    loss_fn=binary_cross_entropy_with_logits,\n",
    "    multi_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.serializer = Labels(labels, multi_label=True, threshold=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nvidia Pytorch tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = flash.Trainer(\n",
    "    max_epochs=10,\n",
    "    auto_lr_find=True,\n",
    "    benchmark=True,\n",
    "    gpus=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.finetune(model, datamodule=dm, strategy=\"freeze_unfreeze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(data_dir/'sample_submission.csv')\n",
    "# submission_df.labels = None\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dataset = PlantDataset(submission_df, TEST_TRANSFORM, 'test')\n",
    "submission_dataloader = DataLoader(submission_dataset, 16, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: create submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_results(submission_dataloader):\n",
    "    results = []\n",
    "    for data in submission_dataloader:\n",
    "        image = data['input']\n",
    "        preds = model(image)\n",
    "        preds = (preds.sigmoid() > 0.5)\n",
    "\n",
    "        for pred in preds:\n",
    "            lab = (df.columns[3:][pred])\n",
    "            results.append(lab.tolist())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.labels = get_results(submission_dataloader)\n",
    "submission_df.labels = submission_df.labels.apply(lambda x: \" \".join(x))\n",
    "submission_df.to_csv(\"/kaggle/working/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
