{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b1dcf00-a529-4893-8cbf-c0f0aa44d2c2",
   "metadata": {},
   "source": [
    "# PyTorch --> PyTorch Lightning\n",
    "\n",
    "## Image Classification with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cfb45a-6e35-4969-9f42-1bedab5ef52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec358d1-cf3b-4a31-9b72-62d780ed97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b28758-075a-42db-8181-9c5fc846590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0afb1b-4f8c-4df1-b611-8b469ab7b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.CIFAR10('/Users/aniket/datasets/',\n",
    "                                          download=True,\n",
    "                                          transform=transform)\n",
    "\n",
    "val_data = torchvision.datasets.CIFAR10('/Users/aniket/datasets/',\n",
    "                                        train=False,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(val_data,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse',\n",
    "           'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70800b-58aa-4366-96bd-5976620a82f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc3e33-6715-4a03-93f0-837fabad8e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ad9ed-37c1-47c7-803c-bd24a30aab7b",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f285a08-695d-4a05-b983-e4813f56ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c913ef3c-ad54-4c19-8eb2-a62aa5b88678",
   "metadata": {},
   "source": [
    "## Define Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3600c65c-728b-4ec7-b279-237b0546b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb53d97-c6b1-4fab-a752-9945df5389ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f9b9d-b865-4cb2-bfd4-219518bb1b26",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d9bae-8d13-4715-90d5-7e18506f66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss\n",
    "def train_step(model, data):\n",
    "    inputs, labels = data\n",
    "\n",
    "    y_pred = net(inputs)\n",
    "    loss = criterion(y_pred, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c9d665-8523-4aee-a6b8-eebe6f172184",
   "metadata": {},
   "source": [
    "# Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02a81d-7823-435d-a8b5-8bd180bab995",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = train_step(net, data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b028d51-7431-48ff-a87c-4553a6c10f81",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c1c89-482c-4895-9a37-2bfb2e27ef2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ⚡️ PyTorch Lightning \n",
    "\n",
    "## Lightning Design Philosophy\n",
    "\n",
    "![Design Phil](https://camo.githubusercontent.com/a3dda9b3053f7093ac1ccc30b41c0f367b171010770252528c30551a2407cad5/68747470733a2f2f706c2d626f6c74732d646f632d696d616765732e73332e75732d656173742d322e616d617a6f6e6177732e636f6d2f7068696c6f736f70686965732e6a7067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb682f0-98e3-4f0f-ac3c-62b22d85ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa04b4a-3a55-4ab3-a95c-dd95538c5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = Net()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        y_pred = self(inputs)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        y_pred = self(inputs)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        \n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams['lr'])\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50256b0a-83a6-4ee3-8574-21a4bd52df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, batch_size: int = 64):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = torchvision.datasets.CIFAR10(\n",
    "            '/Users/aniket/datasets/', download=True, transform=transform)\n",
    "\n",
    "        self.val_data = torchvision.datasets.CIFAR10('/Users/aniket/datasets/',\n",
    "                                                     train=False,\n",
    "                                                     download=True,\n",
    "                                                     transform=transform)\n",
    "        \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_data,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_data,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           shuffle=False)\n",
    "    \n",
    "cifar_dm = CIFARDataModule(batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67bebad-0095-471b-b488-dffc4c3311c2",
   "metadata": {},
   "source": [
    "# Logger & Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b691b5-877c-4873-8223-9ca30f6fb44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger\n",
    "\n",
    "tb_logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "csv_logger = CSVLogger('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf27e91-bc1f-4c31-be67-7efd0a1bb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = LitModel(1e-3)\n",
    "trainer = pl.Trainer(logger=[tb_logger, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c3efd-334f-4ee1-ae43-31dca91f7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(lit_model, datamodule=cifar_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb6e6e-9b5f-4444-b135-a035396e533e",
   "metadata": {},
   "source": [
    "#### References:\n",
    "1. [PyTorch: TRAINING A CLASSIFIER](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9182bf4e-0a5d-4ae0-90c9-18e7bcd80342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
